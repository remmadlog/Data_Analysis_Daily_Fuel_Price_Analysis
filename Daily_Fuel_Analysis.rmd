---
title: "Daily German Fuel Price Analysis (2024)"
output: rmarkdown::github_document
---

## Dataset
The dataset we are using can be found [here](https://dev.azure.com/tankerkoenig/_git/tankerkoenig-data?path=/README.md&_a=preview).
There one can obtain way more data for different years.
We will only focus on the year 2024.

This dataset contains of several ``.csv`` files.
One file per day, sorted in folders by month.
One file is of the following form:

> The head contains:
>
> `date,station_uuid,diesel,e5,e10,dieselchange,e5change,e10change`
>
> Meaning:
>
> |Feld        | Bedeutung                               |
> |------------|-----------------------------------------|
> |date        | Time of change                          |
> |station_uuid| UUID of stations                        |
> |diesel      | Price Diesel                            |
> |e5          | Price Super E5                          |
> |e10         | Price Super E10                         |
> |dieselchange| 0=no change, 1=change, 2=removed, 3=new |
> |e5change    | 0=no change, 1=change, 2=removed, 3=new |
> |e10change   | 0=no change, 1=change, 2=removed, 3=new |


Since the dataset ist quit detailed, and therefor very large (about 11.5GB), we will focus on less information.
We will add a ``date_app`` column that rounds to the full hour and aggregate all by that and brand.
Therefore, we will no longer have the unique station information, but we will end up with a more manageable amount of data.

## Preparation and Transformation

For each month there is a different folder labeled ``01`` to ``12``.
We will do the following:
- iterate over each month ``i in 1:12``
  - get a list of files (one file per day) per folder (one folder per month)
  - open each file (day)
    - join the station information, to obtain the ``brand`` column
    - create a date approximation column ``date_app``, contain date of day and the full hour
    - group by ``date_app`` and ``brand``

The script can be found [here](transforming_cleaning.R)
```r
# joining/merging dataframes
library(dplyr)
# general handling analytics
library(tidyverse)


# open station file
df_station <- read.csv("Datasets/stations.csv")

# initiate an empty dataframe to build upon
df <-  data.frame()

# getting a list of all files per month
# iterating over month
for (i in 1:12){
  # turn the int 3 into the str "03"
  if (i<10){
    folder <- paste0("0", toString(i))
  } else{
    folder <- toString(i)
  }
  path <- paste0("Datasets/2024/", folder)
  list_of_files <- list.files(path =path,
                            pattern = "\\.csv$",
                            full.names = TRUE)

  # iterating over each file (day) for the current month
  for (file_path in list_of_files){
    # open file (daily information)
    df_file <- read.csv(file_path) %>%
            left_join(df_station, by =c("station_uuid"="uuid")) %>%
            select(date, station_uuid, brand, diesel,e5,e10) %>%
            filter(diesel>0.7,
                    diesel<3,
                    e5>0.7,
                    e5<3,
                    e10>0.7,
                    e10<3)   # We do that to avoid foulty outleyers

    # looking at the ``brand`` we notice some whitspace, let's remove it
    df_file$brand <- str_squish(df_file$brand)

    # set date_app YYYY-MM-DD HH
    df_file$date_app <- str_split_i(df_file$date, ":",1)
    temp <- df_file %>%
            group_by(date_app, brand) %>%
            summarise(diesel = mean(diesel),
                      e5 = mean(e5),
                      e10 = mean(e10),
                      gr_size = n())

    # add the day of the week as column
    temp$weekday <- weekdays(as.Date(str_split_i(temp$date_app, " ",1)))

    # add hour column
    temp$hour <- str_split_i(temp$date_app, " ",2)

    # add time of day colums that provides the information of time of day by
    # # night, morning, midday, evening in even 6h chuncks
    # # tod - time of day
    temp$tod <-  NA
    temp$tod[temp$hour %in% c("00", "01", "02", "03", "04", "05")] <- "night"
    temp$tod[temp$hour %in% c("06", "07", "08", "09", "10", "11")] <- "morning"
    temp$tod[temp$hour %in% c("12", "13", "14", "15", "16", "17")] <- "midday"
    temp$tod[temp$hour %in% c("18", "19", "20", "21", "22", "23")] <- "evening"

    # combine df with temp -- add rows from temp
    df <- rbind(df, temp)

    # remove ``temp`` and ``df_file`` from memory
    rm(temp,df_file)
  }
}

write.csv(df,file='Datasets/agg_dataset.csv', row.names=FALSE)
```


## Analysis
With the creation of our dataframe behind us, we will now process to do some analysis.
To be more precise we will have a look at the following:
- price per fuel per
  - ``hour``
  - ``weekday``
  - ``tod`` (time of day)
- price per fuel per ``brand`` per
  - ``hour``
  - ``weekday``
  - ``tod`` (time of day)
- price per fuel per brand over time

The main question ``When and where to refuel?`` we be answered during this investigation.

We start by loading the ``tidyverse`` library and reading the aggregated CSV file.
```{r warning=FALSE,message=FALSE}
# general handling analytics
library(tidyverse)

# open station file
df <- read.csv("Datasets/agg_dataset.csv")
```

### Fuel Price by Weekday
We group by ``weekday`` and consider the average fuel price.
```{r warning=FALSE,message=FALSE}
df %>%
    group_by(weekday) %>%
    summarise(diesel=mean(diesel),
              e5=mean(e5),
              e10=mean(e10))
```
```{r}
print(head(df,7))
```

We notice that there is not a huge differance in pricing.
This might be due to larger differences in prices per month.

To see if that might be the case, we first add the column ``month``
```{r}
df$month <- str_split_i(df$date_app, "-",2)
```

Then we take the average:
```{r warning=FALSE,message=FALSE}
df %>%
        group_by(month) %>%
    summarise(diesel=mean(diesel),
              e5=mean(e5),
              e10=mean(e10))
```
```{r}
print(head(df,12))
```

So averaging over, e.g., every **monday**, results in an outcome that's to flat.

We will try to count the weekdays that are lowest per week.
For that we need to know the numer of the week:
```{r}
df$nweek <- strftime(str_split_i(df$date_app, " ",1), format = "%V")
```


Let us focus in **e10** for a moment.

Next we filter by ``nweek`` and ``week``, form the average and consider columns were the minimum for each group is present.
Then we group by ``weekday`` to count the entries.
We should end up with a list of weekdays and how often they were the lowest price
```{r warning=FALSE,message=FALSE}
df_weekdays <- df %>%
    group_by(nweek, weekday) %>%
    summarise(e10=mean(e10)) %>%
    filter(e10 == min(e10, na.rm=TRUE)) %>%
    group_by(weekday) %>%
    summarise(amount_e10 = n()) %>%
    arrange(desc(amount_e10))
```

For **e10** we see that **Mondays** and **Tuesdays** are the best ways to refile in general.

Doing the same for **diesel** and **e5**:
```{r warning=FALSE,message=FALSE}
temp <- df %>%
    group_by(nweek, weekday) %>%
    summarise(e5=mean(e5)) %>%
    filter(e5 == min(e5, na.rm=TRUE)) %>%
    group_by(weekday) %>%
    summarise(amount_e5 = n()) %>%
    arrange(desc(amount_e5))

df_weekdays <- left_join(df_weekdays,temp, by = "weekday")

temp <- df %>%
    group_by(nweek, weekday) %>%
    summarise(diesel=mean(diesel)) %>%
    filter(diesel == min(diesel, na.rm=TRUE)) %>%
    group_by(weekday) %>%
    summarise(amount_diesel = n()) %>%
    arrange(desc(amount_diesel))

df_weekdays <- left_join(df_weekdays,temp, by = "weekday")
```

Print the results:
```{r}
print(df_weekdays)
```


Using this procedure we continue to figure out the best time to refuel.
### Best Time of Day to Refuel

Adding a ``day`` column.
```{r warning=FALSE,message=FALSE}
df$day <- str_split_i(df$date_app, " ",1)
```

Then following the same idea as before.
Considering the following table,
```{r warning=FALSE,message=FALSE}
df_tod <- df %>%
    group_by(day, tod) %>%
    summarise(e10=mean(e10)) %>%
    filter(e10 == min(e10)) %>%
    group_by(tod) %>%
    summarise(amount_e10 = n()) %>%
    arrange(desc(amount_e10))

temp <- df %>%
    group_by(day, tod) %>%
    summarise(e5=mean(e5)) %>%
    filter(e5 == min(e5)) %>%
    group_by(tod) %>%
    summarise(amount_e5 = n()) %>%
    arrange(desc(amount_e5))

df_tod <- left_join(df_tod, temp, by="tod")


temp <- df %>%
    group_by(day, tod) %>%
    summarise(diesel=mean(diesel)) %>%
    filter(diesel == min(diesel)) %>%
    group_by(tod) %>%
    summarise(amount_diesel = n()) %>%
    arrange(desc(amount_diesel))

df_tod <- left_join(df_tod, temp, by="tod")
```

Printing the output
```{r}
print(df_tod)
```
We notice that the best time of day is **evening**.
Refueling in the evening is cheaper for 366 out of 366 days in 2024.


### Best Time to Refuel
We learned the day and the general time of day to refuel.
Next we will see at witch exact hour of the day one should refill.
```{r warning=FALSE,message=FALSE}
df_h <- df %>%
    group_by(day, hour) %>%
    summarise(e10=mean(e10)) %>%
    filter(e10 == min(e10)) %>%
    group_by(hour) %>%
    summarise(amount_e10 = n()) %>%
    arrange(desc(amount_e10))

temp <- df %>%
    group_by(day, hour) %>%
    summarise(e5=mean(e5)) %>%
    filter(e5 == min(e5)) %>%
    group_by(hour) %>%
    summarise(amount_e5 = n()) %>%
    arrange(desc(amount_e5))

df_h <- left_join(df_h, temp, by="hour")


temp <- df %>%
    group_by(day, hour) %>%
    summarise(diesel=mean(diesel)) %>%
    filter(diesel == min(diesel)) %>%
    group_by(hour) %>%
    summarise(amount_diesel = n()) %>%
    arrange(desc(amount_diesel))

df_h <- left_join(df_h, temp, by="hour")
```

Having a look at the table
```{r}
print(df_h)
```
we notice that best time to refuel is a 09:00pm.

### Best combination

We do the same as before but we group for all components, namely for ``nweek, weekday, tod`` and ``hour``.
In order to calculate a average price.
Then match it with the minimum per group, that is given by ``weekday, tod`` and ``hour``.
Counting the amount of occupying minima we obtain the following:
```{r warning=FALSE,message=FALSE}
df_comb_e10 <- df %>%
    group_by(nweek, weekday, tod, hour) %>%
    summarise(e10=mean(e10)) %>%
    filter(e10 == min(e10)) %>%
    group_by(weekday, tod, hour) %>%
    summarise(amount_e10 = n(), av_e10 = mean(e10)) %>%
    arrange(desc(amount_e10))
```
```{r}
print(head(df_comb_e10,10))
```

Doing the same for **e5** and **diesel:
```{r warning=FALSE,message=FALSE}
df_comb_e5 <- df %>%
    group_by(nweek, weekday, tod, hour) %>%
    summarise(e5=mean(e5)) %>%
    filter(e5 == min(e5)) %>%
    group_by(weekday, tod, hour) %>%
    summarise(amount_e5 = n(), av_e5 = mean(e5)) %>%
    arrange(desc(amount_e5))
```
```{r}
print(head(df_comb_e5,10))
```


```{r warning=FALSE,message=FALSE}
df_comb_diesel <- df %>%
    group_by(nweek, weekday, tod, hour) %>%
    summarise(diesel=mean(diesel)) %>%
    filter(diesel == min(diesel)) %>%
    group_by(weekday, tod, hour) %>%
    summarise(amount_diesel = n(), av_diesel = mean(diesel)) %>%
    arrange(desc(amount_diesel))
```
```{r}
print(head(df_comb_diesel,10))
```