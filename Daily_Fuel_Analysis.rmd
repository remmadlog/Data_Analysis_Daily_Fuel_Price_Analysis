---
title: "Daily German Fuel Price Analysis (2024)"
output: rmarkdown::github_document
---

# TOC
<details>
  <summary>Click to show</summary>

- [Dataset](#dataset)
- [When Should You Refuel?](#when-should-you-refuel)
  * [Preparation and Transformation](#preparation-and-transformation)
  * [Analysis](#analysis)
    + [Fuel Price by Weekday](#fuel-price-by-weekday)
    + [Best Time of Day to Refuel](#best-time-of-day-to-refuel)
    + [Best Time to Refuel](#best-time-to-refuel)
    + [Best combination](#best-combination)
- [Where to Refuel?](#where-to-refuel)
  * [Brand Analysis](#brand-analysis)

</details>

---

# Dataset
The dataset we are using can be found [here](https://dev.azure.com/tankerkoenig/_git/tankerkoenig-data?path=/README.md&_a=preview).
There one can obtain way more data for different years.
We will only focus on the year 2024.

This dataset contains of several ``.csv`` files.
One file per day, sorted in folders by month.
One file is of the following form:

> The head contains:
>
> `date,station_uuid,diesel,e5,e10,dieselchange,e5change,e10change`
>
> Meaning:
>
> |Feld        | Bedeutung                               |
> |------------|-----------------------------------------|
> |date        | Time of change                          |
> |station_uuid| UUID of stations                        |
> |diesel      | Price Diesel                            |
> |e5          | Price Super E5                          |
> |e10         | Price Super E10                         |
> |dieselchange| 0=no change, 1=change, 2=removed, 3=new |
> |e5change    | 0=no change, 1=change, 2=removed, 3=new |
> |e10change   | 0=no change, 1=change, 2=removed, 3=new |


Since the dataset ist quit detailed, and therefor very large (about 11.5GB), we will focus on less information.
We will add a ``date_app`` column that rounds to the full hour and aggregate all by that and brand.
Therefore, we will no longer have the unique station information, but we will end up with a more manageable amount of data.

# When Should You Refuel?

## Preparation and Transformation

For each month there is a different folder labeled ``01`` to ``12``.
We will do the following:
- iterate over each month ``i in 1:12``
  - get a list of files (one file per day) per folder (one folder per month)
  - open each file (day)
    - join the station information, to obtain the ``brand`` column
    - create a date approximation column ``date_app``, contain date of day and the full hour
    - group by ``date_app`` and ``brand``

The script can be found [here](transforming_cleaning_agg_date_brand.R)
```r
# joining/merging dataframes
library(dplyr)
# general handling analytics
library(tidyverse)


# open station file
df_station <- read.csv("Datasets/stations.csv")

# initiate an empty dataframe to build upon
df <-  data.frame()

# getting a list of all files per month
# iterating over month
for (i in 1:12){
  # turn the int 3 into the str "03"
  if (i<10){
    folder <- paste0("0", toString(i))
  } else{
    folder <- toString(i)
  }
  path <- paste0("Datasets/2024/", folder)
  list_of_files <- list.files(path =path,
                            pattern = "\\.csv$",
                            full.names = TRUE)

  # iterating over each file (day) for the current month
  for (file_path in list_of_files){
    # open file (daily information)
    df_file <- read.csv(file_path) %>%
            left_join(df_station, by =c("station_uuid"="uuid")) %>%
            select(date, station_uuid, brand, diesel,e5,e10) %>%
            filter(diesel>0.7,
                    diesel<3,
                    e5>0.7,
                    e5<3,
                    e10>0.7,
                    e10<3)   # We do that to avoid foulty outleyers

    # looking at the ``brand`` we notice some whitspace, let's remove it
    df_file$brand <- str_squish(df_file$brand)

    # set date_app YYYY-MM-DD HH
    df_file$date_app <- str_split_i(df_file$date, ":",1)
    temp <- df_file %>%
            group_by(date_app, brand) %>%
            summarise(diesel = mean(diesel),
                      e5 = mean(e5),
                      e10 = mean(e10),
                      gr_size = n())

    # add the day of the week as column
    temp$weekday <- weekdays(as.Date(str_split_i(temp$date_app, " ",1)))

    # add hour column
    temp$hour <- str_split_i(temp$date_app, " ",2)

    # add time of day colums that provides the information of time of day by
    # # night, morning, midday, evening in even 6h chuncks
    # # tod - time of day
    temp$tod <-  NA
    temp$tod[temp$hour %in% c("00", "01", "02", "03", "04", "05")] <- "night"
    temp$tod[temp$hour %in% c("06", "07", "08", "09", "10", "11")] <- "morning"
    temp$tod[temp$hour %in% c("12", "13", "14", "15", "16", "17")] <- "midday"
    temp$tod[temp$hour %in% c("18", "19", "20", "21", "22", "23")] <- "evening"

    # combine df with temp -- add rows from temp
    df <- rbind(df, temp)

    # remove ``temp`` and ``df_file`` from memory
    rm(temp,df_file)
  }
}

write.csv(df,file='Datasets/agg_dataset.csv', row.names=FALSE)
```


## Analysis
With the creation of our dataframe behind us, we will now process to do some analysis.
To be more precise we will have a look at the following:
- price per fuel per
  - ``hour``
  - ``weekday``
  - ``tod`` (time of day)
- price per fuel per ``brand`` per
  - ``hour``
  - ``weekday``
  - ``tod`` (time of day)
- price per fuel per brand over time

The main question ``When and where to refuel?`` we be answered during this investigation.

We start by loading the ``tidyverse`` library and reading the aggregated CSV file.
```{r warning=FALSE,message=FALSE}
# general handling analytics
library(tidyverse)

# open station file
df <- read.csv("Datasets/agg_dataset.csv")
```

### Fuel Price by Weekday
We group by ``weekday`` and consider the average fuel price.
```{r warning=FALSE,message=FALSE}
df %>%
    group_by(weekday) %>%
    summarise(diesel=mean(diesel),
              e5=mean(e5),
              e10=mean(e10))
```
```{r}
print(head(df,7))
```

We notice that there is not a huge differance in pricing.
This might be due to larger differences in prices per month.

To see if that might be the case, we first add the column ``month``
```{r}
df$month <- str_split_i(df$date_app, "-",2)
```

Then we take the average:
```{r warning=FALSE,message=FALSE}
df %>%
        group_by(month) %>%
    summarise(diesel=mean(diesel),
              e5=mean(e5),
              e10=mean(e10))
```
```{r}
print(head(df,12))
```

So averaging over, e.g., every **monday**, results in an outcome that's to flat.

We will try to count the weekdays that are lowest per week.
For that we need to know the numer of the week:
```{r}
df$nweek <- strftime(str_split_i(df$date_app, " ",1), format = "%V")
```


Let us focus in **e10** for a moment.

Next we filter by ``nweek`` and ``week``, form the average and consider columns were the minimum for each group is present.
Then we group by ``weekday`` to count the entries.
We should end up with a list of weekdays and how often they were the lowest price
```{r warning=FALSE,message=FALSE}
df_weekdays <- df %>%
    group_by(nweek, weekday) %>%
    summarise(e10=mean(e10)) %>%
    filter(e10 == min(e10, na.rm=TRUE)) %>%
    group_by(weekday) %>%
    summarise(amount_e10 = n()) %>%
    arrange(desc(amount_e10))
```

For **e10** we see that **Mondays** and **Tuesdays** are the best ways to refile in general.

Doing the same for **diesel** and **e5**:
```{r warning=FALSE,message=FALSE}
temp <- df %>%
    group_by(nweek, weekday) %>%
    summarise(e5=mean(e5)) %>%
    filter(e5 == min(e5, na.rm=TRUE)) %>%
    group_by(weekday) %>%
    summarise(amount_e5 = n()) %>%
    arrange(desc(amount_e5))

df_weekdays <- left_join(df_weekdays,temp, by = "weekday")

temp <- df %>%
    group_by(nweek, weekday) %>%
    summarise(diesel=mean(diesel)) %>%
    filter(diesel == min(diesel, na.rm=TRUE)) %>%
    group_by(weekday) %>%
    summarise(amount_diesel = n()) %>%
    arrange(desc(amount_diesel))

df_weekdays <- left_join(df_weekdays,temp, by = "weekday")
```

Print the results:
```{r}
print(df_weekdays)
```


Using this procedure we continue to figure out the best time to refuel.
### Best Time of Day to Refuel

Adding a ``day`` column.
```{r warning=FALSE,message=FALSE}
df$day <- str_split_i(df$date_app, " ",1)
```

Then following the same idea as before.
Considering the following table,
```{r warning=FALSE,message=FALSE}
df_tod <- df %>%
    group_by(day, tod) %>%
    summarise(e10=mean(e10)) %>%
    filter(e10 == min(e10)) %>%
    group_by(tod) %>%
    summarise(amount_e10 = n()) %>%
    arrange(desc(amount_e10))

temp <- df %>%
    group_by(day, tod) %>%
    summarise(e5=mean(e5)) %>%
    filter(e5 == min(e5)) %>%
    group_by(tod) %>%
    summarise(amount_e5 = n()) %>%
    arrange(desc(amount_e5))

df_tod <- left_join(df_tod, temp, by="tod")


temp <- df %>%
    group_by(day, tod) %>%
    summarise(diesel=mean(diesel)) %>%
    filter(diesel == min(diesel)) %>%
    group_by(tod) %>%
    summarise(amount_diesel = n()) %>%
    arrange(desc(amount_diesel))

df_tod <- left_join(df_tod, temp, by="tod")
```

Printing the output
```{r}
print(df_tod)
```
We notice that the best time of day is **evening**.
Refueling in the evening is cheaper for 366 out of 366 days in 2024.


### Best Time to Refuel
We learned the day and the general time of day to refuel.
Next we will see at witch exact hour of the day one should refill.
```{r warning=FALSE,message=FALSE}
df_h <- df %>%
    group_by(day, hour) %>%
    summarise(e10=mean(e10)) %>%
    filter(e10 == min(e10)) %>%
    group_by(hour) %>%
    summarise(amount_e10 = n()) %>%
    arrange(desc(amount_e10))

temp <- df %>%
    group_by(day, hour) %>%
    summarise(e5=mean(e5)) %>%
    filter(e5 == min(e5)) %>%
    group_by(hour) %>%
    summarise(amount_e5 = n()) %>%
    arrange(desc(amount_e5))

df_h <- left_join(df_h, temp, by="hour")


temp <- df %>%
    group_by(day, hour) %>%
    summarise(diesel=mean(diesel)) %>%
    filter(diesel == min(diesel)) %>%
    group_by(hour) %>%
    summarise(amount_diesel = n()) %>%
    arrange(desc(amount_diesel))

df_h <- left_join(df_h, temp, by="hour")
```

Having a look at the table
```{r}
print(df_h)
```
we notice that best time to refuel is a 09:00pm.

### Best combination

We do the same as before but we group for all components, namely for ``nweek, weekday, tod`` and ``hour``.
In order to calculate a average price.
Then match it with the minimum per group, that is given by ``weekday, tod`` and ``hour``.
Counting the amount of occupying minima we obtain the following:
```{r warning=FALSE,message=FALSE}
df_comb_e10 <- df %>%
    group_by(nweek, weekday, tod, hour) %>%
    summarise(e10=mean(e10)) %>%
    filter(e10 == min(e10)) %>%
    group_by(weekday, tod, hour) %>%
    summarise(amount_e10 = n(), av_e10 = mean(e10)) %>%
    arrange(desc(amount_e10))
```
```{r}
print(head(df_comb_e10,10))
```

Doing the same for **e5** and **diesel:
```{r warning=FALSE,message=FALSE}
df_comb_e5 <- df %>%
    group_by(nweek, weekday, tod, hour) %>%
    summarise(e5=mean(e5)) %>%
    filter(e5 == min(e5)) %>%
    group_by(weekday, tod, hour) %>%
    summarise(amount_e5 = n(), av_e5 = mean(e5)) %>%
    arrange(desc(amount_e5))
```
```{r}
print(head(df_comb_e5,10))
```


```{r warning=FALSE,message=FALSE}
df_comb_diesel <- df %>%
    group_by(nweek, weekday, tod, hour) %>%
    summarise(diesel=mean(diesel)) %>%
    filter(diesel == min(diesel)) %>%
    group_by(weekday, tod, hour) %>%
    summarise(amount_diesel = n(), av_diesel = mean(diesel)) %>%
    arrange(desc(amount_diesel))
```
```{r}
print(head(df_comb_diesel,10))
```



# Where to Refuel?

## Brand Analysis

We start by calculating the brands with the highest amount of having the lowest price per day for e10.
Here is no consideration of how common the brand is or how many stations there are

```{r warning=FALSE,message=FALSE}
temp <- df %>%
  group_by(day,brand) %>%                         # group brand per day
  summarise(e10 = mean(e10)) %>%                  # calculate av price for each entry -> ungroups subgroup (brand)
  filter(e10 == min(e10)) %>%                     # find min for each group (day)
  group_by(brand) %>%                             # groups each brand over possible 366 days
  summarise(e10 = mean(e10), size=n()) %>%        # calculate av price per brand and count group size (how often was it min)
  arrange(desc(size))
```

Having a look at the output:
```{r}
print(head(temp,6))
```



In order to take the amount of stations by brand in consideration we consider ``stations.csv``.
```{r warning=FALSE,message=FALSE}
df_station <- read.csv("Datasets/stations.csv")

df_brand_size <- df_station %>%
  filter(brand!="") %>%           # rmoving unknown brands (blank)
  group_by(brand) %>%
  summarise(size=n()) %>%         # count how many stations are there (size of group)
  arrange(desc(size))
```


We will only consider brand with more than ``fsize`` stations.
In our case we set ``fsize = 300``.

```{r warning=FALSE,message=FALSE}
fsize <- 300

df_brand_size_fsize <- df_brand_size %>%
  filter(size >= fsize)
```

Repeating the evaluation from before, but only considering brand with 300 or more stations.
```{r warning=FALSE,message=FALSE}
temp <- df %>%
  filter(brand %in% df_brand_size_fsize$brand) %>%
  group_by(day,brand) %>%                         # group brand per day
  summarise(e10 = mean(e10))  %>%                 # calculate av price for each entry -> ungroups subgroup (brand)
  filter(e10 == min(e10)) %>%                     # find min for each group (day)
  group_by(brand) %>%                             # groups each brand over possible 366 days
  summarise(e10 = mean(e10), size=n()) %>%        # calculate av price per brand and count group size (how often was it min)
  arrange(desc(size))
```

Leads to the following:
```{r}
print(head(temp,6))
```


We see that **JET** is on **211** days the cheapest brand on average for e10, out of 366 possible days of 2024.

For **e5** and **diesel** we are following the example above:
```{r warning=FALSE,message=FALSE}
temp_e5 <- df %>%
  filter(brand %in% df_brand_size_fsize$brand) %>%
  group_by(day,brand) %>%                         # group brand per day
  summarise(e5 = mean(e5))  %>%                 # calculate av price for each entry -> ungroups subgroup (brand)
  filter(e5 == min(e5)) %>%                     # find min for each group (day)
  group_by(brand) %>%                             # groups each brand over possible 366 days
  summarise(e5 = mean(e5), size=n()) %>%        # calculate av price per brand and count group size (how often was it min)
  arrange(desc(size))

temp_diesel <- df %>%
  filter(brand %in% df_brand_size_fsize$brand) %>%
  group_by(day,brand) %>%                         # group brand per day
  summarise(diesel = mean(diesel))  %>%                 # calculate av price for each entry -> ungroups subgroup (brand)
  filter(diesel == min(diesel)) %>%                     # find min for each group (day)
  group_by(brand) %>%                             # groups each brand over possible 366 days
  summarise(diesel = mean(diesel), size=n()) %>%        # calculate av price per brand and count group size (how often was it min)
  arrange(desc(size))

```

Leads to the following:
```{r}
print(head(temp_e5,6))
```
```{r}
print(head(temp_diesel,6))
```










